#!/usr/bin/env python3
"""
REST API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YOLOv8 –∏ Flask.
"""

import os
import io
import base64
from pathlib import Path
from datetime import datetime
import cv2
import numpy as np
from PIL import Image
from flask import Flask, request, jsonify
from flask_cors import CORS
from ultralytics import YOLO
import json
import google.generativeai as genai

try:
    GEMINI_API_KEY = "AIzaSyC6Ja-qGbZWCDSDEZlPN3gwYMUxAWckhXQ"
    # GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
    # if not GEMINI_API_KEY:
    #     raise ValueError("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        
    genai.configure(api_key=GEMINI_API_KEY)
    
    SYSTEM_PROMPT = """You are a senior AI quality control specialist. Your task is to provide a final, comprehensive report for an end-user based on two sources of information: an original user-uploaded IMAGE and a JSON_DATA report from a preliminary ML detection model.

    1.  **Analyze the IMAGE:** First, personally inspect the provided IMAGE for any visible paint defects (like scratches, dents, bubbling, etc.).
    2.  **Analyze the JSON_DATA:** Second, review the `detections` and `class_counts` from the `JSON_DATA` provided by the local ML model.
    3.  **Synthesize and Report:** Combine your own visual analysis with the model's data to create a single, detailed report.
        * State the total defects found by the local model (`total_defects`).
        * If the local model's detections (e.g., `class: "bubbling"`) match what you see in the IMAGE, confirm this (e.g., "The model correctly identified 'bubbling'").
        * If the local model missed something you see, point it out (e.g., "In addition to the model's findings, I also observe a 'scratch' that was not flagged").
        * If the local model's finding seems incorrect or has low confidence, add your assessment.
        * If no defects are found by either you or the model, congratulate the user.
        * Conclude by informing the user that a processed image with the *model's* detections highlighted (`result_image`) is also available.
    4.  **Tone:** Be professional, polite, and informative.
    5.  **CRITICAL INSTRUCTION:** You must provide your entire final response in the Russian language.
    """
    
    gemini_model = genai.GenerativeModel(
        model_name="models/gemini-flash-latest",  # <-- –í–æ—Ç —Ç–æ—á–Ω–æ–µ –∏–º—è
        system_instruction=SYSTEM_PROMPT
    )
    print("–ö–ª–∏–µ–Ω—Ç Gemini —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω.")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Gemini: {e}")
    gemini_model = None
# -----------------------------

class PaintDefectDetector:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏"""
    
    def __init__(self, model_path: str):
        self.model_path = Path(model_path)
        self.model = None
        self.class_names = [
            'scratch',           # —Ü–∞—Ä–∞–ø–∏–Ω—ã
            'dent',             # –≤–º—è—Ç–∏–Ω—ã  
            'paint_run',        # –ø–æ–¥—Ç—ë–∫–∏ –∫—Ä–∞—Å–∫–∏
            'undercoat_missing', # –Ω–µ–ø—Ä–æ–∫—Ä–∞—Å—ã
            'contamination',    # —Å–æ—Ä–Ω–æ—Å—Ç—å
            'bubbling'          # –≤—Å–ø—É—á–∏–≤–∞–Ω–∏–µ
        ]
        
        # –¶–≤–µ—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)
        self.colors = {
            'scratch': (0, 0, 255),           # –∫—Ä–∞—Å–Ω—ã–π
            'dent': (255, 0, 0),             # —Å–∏–Ω–∏–π
            'paint_run': (0, 255, 255),      # –∂–µ–ª—Ç—ã–π
            'undercoat_missing': (255, 0, 255), # –º–∞–≥–µ–Ω—Ç–∞
            'contamination': (0, 255, 0),    # –∑–µ–ª–µ–Ω—ã–π
            'bubbling': (255, 165, 0)        # –æ—Ä–∞–Ω–∂–µ–≤—ã–π
        }
        
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not self.model_path.exists():
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
        
        try:
            self.model = YOLO(str(self.model_path))
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if len(image.shape) == 3 and image.shape[2] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        return image
    
    def detect_defects(self, image: np.ndarray, confidence_threshold: float = 0.5):
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_image = self.preprocess_image(image)
        
        # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
        results = self.model(processed_image, conf=confidence_threshold)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        detections = []
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    class_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
                    class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                    
                    detection = {
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'class': class_name,
                        'confidence': confidence,
                        'class_id': class_id
                    }
                    
                    detections.append(detection)
        
        return detections
    
    def draw_detections(self, image: np.ndarray, detections: list) -> np.ndarray:
        """–†–∏—Å—É–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        result_image = image.copy()
        
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            class_name = detection['class']
            confidence = detection['confidence']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∞
            color = self.colors.get(class_name, (128, 128, 128))
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(result_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            label = f"{class_name}: {confidence:.2f}"
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            
            # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(
                result_image,
                (int(x1), int(y1) - text_height - baseline - 5),
                (int(x1) + text_width, int(y1)),
                color,
                -1
            )
            
            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
            cv2.putText(
                result_image,
                label,
                (int(x1), int(y1) - baseline - 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )
        
        return result_image


# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)
CORS(app)  # –†–∞–∑—Ä–µ—à–∞–µ–º CORS –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
MODEL_PATH = Path(__file__).parent / "models" / "paint_defect.pt"
detector = None

try:
    if MODEL_PATH.exists():
        detector = PaintDefectDetector(str(MODEL_PATH))
    else:
        print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")
        print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python utils/train_model.py")
except Exception as e:
    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {e}")

@app.route('/')
def index():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API"""
    return jsonify({
        'name': 'Paint Defect Detection API',
        'version': '1.0.0',
        'description': 'REST API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π',
        'endpoints': {
            'POST /api/detect': '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏',
            'GET /api/model_info': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏',
            'GET /api/health': '–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è API'
        },
        'model_loaded': detector is not None,
        'gemini_loaded': gemini_model is not None,
        'timestamp': datetime.now().isoformat()
    })


@app.route('/api/detect', methods=['POST'])
def detect_defects():
    """API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    
    if detector is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ü–∏–∏ (detector) –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.', 'success': False}), 500
    
    if gemini_model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å Gemini –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API-–∫–ª—é—á.', 'success': False}), 500
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if 'image' not in request.files:
            return jsonify({
                'error': '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'success': False
            }), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({
                'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω',
                'success': False
            }), 400
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        confidence_threshold = float(request.form.get('confidence', 0.5))
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_bytes = file.read()

        image = Image.open(io.BytesIO(image_bytes))
        
        image_np = np.array(image)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR –¥–ª—è OpenCV
        if len(image_np.shape) == 3:
            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        
        # –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –¥–µ—Ñ–µ–∫—Ç—ã
        detections = detector.detect_defects(image_np, confidence_threshold)
        
        # –†–∏—Å—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_image = detector.draw_detections(image_np, detections)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ base64
        _, buffer = cv2.imencode('.jpg', result_image)
        result_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        defect_counts = {}
        for detection in detections:
            class_name = detection['class']
            defect_counts[class_name] = defect_counts.get(class_name, 0) + 1
            

        total_defects = len(detections)
        
        ml_output_data = {
            'success': True,
            'detections': detections,
            'class_counts': defect_counts, 
            'total_defects': total_defects,
            'image_with_detections_available': True 
        }

        json_string = json.dumps(ml_output_data, ensure_ascii=False, indent=2)

        gemini_user_prompt_text = f"""
        Here is the JSON_DATA from our local detection model:
        ```json
        {json_string}
        Please analyze this JSON_DATA along with the provided user IMAGE and generate the final report as per your instructions. """
        
        image_pil_for_mime = Image.open(io.BytesIO(image_bytes))
        image_mime_type = Image.MIME.get(image_pil_for_mime.format)

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        if image_mime_type not in ['image/jpeg', 'image/png']:
            image_mime_type = 'image/jpeg' # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        image_part = {
            "mime_type": image_mime_type,
            "data": image_bytes
        }

        gemini_report = ""
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫: [—Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]
            response = gemini_model.generate_content([
                gemini_user_prompt_text, # –ß–∞—Å—Ç—å 1: –¢–µ–∫—Å—Ç (JSON)
                image_part               # –ß–∞—Å—Ç—å 2: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            ])
            gemini_report = response.text
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API: {e}")
            gemini_report = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç."
            
        # –¥–∞–Ω–Ω—ã–µ —Ñ—Ä–æ–Ω—Ç—É
        return jsonify({
            'success': True,
            'detections': detections,       # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'defect_counts': defect_counts, # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'total_defects': total_defects, # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'result_image': result_base64,  # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'gemini_report': gemini_report, # <-- –û—Ç—á–µ—Ç –æ—Ç Gemini
            'timestamp': datetime.now().isoformat()
        })


    
    except Exception as e:
        return jsonify({
            'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}',
            'success': False
        }), 500


@app.route('/api/model_info')
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if detector is None:
        return jsonify({
            'loaded': False,
            'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'
        })
    
    return jsonify({
        'loaded': True,
        'model_path': str(detector.model_path),
        'classes': detector.class_names,
        'colors': {k: [int(c) for c in v] for k, v in detector.colors.items()}
    })


@app.route('/api/health')
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': detector is not None,
        'timestamp': datetime.now().isoformat()
    })


@app.errorhandler(413)
def too_large(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    return jsonify({
        'error': '–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 16MB',
        'success': False
    }), 413


@app.errorhandler(404)
def not_found(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ 404 –æ—à–∏–±–æ–∫"""
    return jsonify({
        'error': 'Endpoint –Ω–µ –Ω–∞–π–¥–µ–Ω',
        'success': False,
        'available_endpoints': [
            'GET /',
            'POST /api/detect',
            'GET /api/model_info',
            'GET /api/health'
        ]
    }), 404


@app.errorhandler(500)
def internal_error(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –æ—à–∏–±–æ–∫"""
    return jsonify({
        'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞',
        'success': False
    }), 500


if __name__ == '__main__':
    print("="*60)
    print("–°–ò–°–¢–ï–ú–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –î–ï–§–ï–ö–¢–û–í –û–ö–†–ê–°–ö–ò –ê–í–¢–û–ú–û–ë–ò–õ–ï–ô")
    print("="*60)
    
    if detector is not None:
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print(f"   –ö–ª–∞—Å—Å—ã –¥–µ—Ñ–µ–∫—Ç–æ–≤: {', '.join(detector.class_names)}")
    else:
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        print("   –î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print("   1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ .env —Ñ–∞–π–ª —Å API –∫–ª—é—á–æ–º Roboflow")
        print("   2. python utils/merge_datasets.py")
        print("   3. python utils/train_model.py")
    
    print("\nüåê –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞...")
    print("   URL: http://localhost:5000")
    print("   –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    print("="*60)
    
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=True,
        threaded=True
    )