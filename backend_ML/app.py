#!/usr/bin/env python3
"""
REST API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YOLOv8 –∏ Flask.
"""

import os
import io
import base64
from pathlib import Path
from datetime import datetime
import cv2
import numpy as np
from PIL import Image
from flask import Flask, request, jsonify, Response, send_from_directory
from flask_cors import CORS
from ultralytics import YOLO
import json
import google.generativeai as genai

try:
    GEMINI_API_KEY = "AIzaSyC6Ja-qGbZWCDSDEZlPN3gwYMUxAWckhXQ"
    # GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
    # if not GEMINI_API_KEY:
    #     raise ValueError("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        
    genai.configure(api_key=GEMINI_API_KEY)
    
    SYSTEM_PROMPT = """You are an expert AI quality control analyst. Your task is to provide a concise and professional analysis of a vehicle's paint condition based on an uploaded IMAGE and a JSON_DATA report from a detection model.

    **Instructions:**

    1.  **Primary Analysis:** Review the `JSON_DATA` from the local model to understand its findings (`total_defects`, `detections`, `class_counts`).
    2.  **Visual Verification:** Briefly cross-reference the model's findings with your own inspection of the `IMAGE`.
    3.  **Synthesize a Professional Summary:** Generate a brief, expert summary in Russian.
        *   Start with a clear, one-sentence overview of the paint condition.
        *   Succinctly list the key defects identified by the model, confirming if they are visually accurate.
        *   If you notice any significant discrepancies (e.g., obvious defects missed by the model, or clear false positives), mention them briefly.
        *   Avoid conversational filler. Be direct and data-driven.
        *   If no defects are found, state it clearly and professionally.
        *   Conclude by mentioning that a processed image with highlighted detections is available.

    **Tone:** Professional, concise, and authoritative.

    **CRITICAL INSTRUCTION:** The entire response must be in Russian.
    """
    
    gemini_model = genai.GenerativeModel(
        model_name="models/gemini-flash-latest",  # <-- –í–æ—Ç —Ç–æ—á–Ω–æ–µ –∏–º—è
        system_instruction=SYSTEM_PROMPT
    )
    print("–ö–ª–∏–µ–Ω—Ç Gemini —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω.")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Gemini: {e}")
    gemini_model = None
# -----------------------------

DATA_STORAGE_PATH = Path(__file__).parent / "detection_data.json"

def save_detection_data(data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤ JSON-—Ñ–∞–π–ª."""
    try:
        if DATA_STORAGE_PATH.exists():
            with open(DATA_STORAGE_PATH, 'r', encoding='utf-8') as f:
                records = json.load(f)
        else:
            records = []
        
        records.append(data)
        
        with open(DATA_STORAGE_PATH, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=4)
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")


class PaintDefectDetector:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏"""
    
    def __init__(self, model_path: str):
        self.model_path = Path(model_path)
        self.model = None
        self.class_names = [
            'scratch',           # —Ü–∞—Ä–∞–ø–∏–Ω—ã
            'dent',             # –≤–º—è—Ç–∏–Ω—ã  
            'runs',             # –ø–æ–¥—Ç—ë–∫–∏ –∫—Ä–∞—Å–∫–∏
            'bubbling'          # –≤—Å–ø—É—á–∏–≤–∞–Ω–∏–µ
        ]
        
        # –¶–≤–µ—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)
        self.colors = {
            'scratch': (0, 0, 255),           # –∫—Ä–∞—Å–Ω—ã–π
            'dent': (255, 0, 0),             # —Å–∏–Ω–∏–π
            'runs': (0, 255, 255),           # –∂–µ–ª—Ç—ã–π
            'bubbling': (255, 165, 0)        # –æ—Ä–∞–Ω–∂–µ–≤—ã–π
        }
        
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not self.model_path.exists():
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
        
        try:
            self.model = YOLO(str(self.model_path))
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if len(image.shape) == 3 and image.shape[2] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        return image
    
    def detect_defects(self, image: np.ndarray, confidence_threshold: float = 0.5):
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_image = self.preprocess_image(image)
        
        # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
        results = self.model(processed_image, conf=confidence_threshold)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        detections = []
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    class_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
                    class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                    
                    detection = {
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'class': class_name,
                        'confidence': confidence,
                        'class_id': class_id
                    }
                    
                    detections.append(detection)
        
        return detections
    
    def draw_detections(self, image: np.ndarray, detections: list) -> np.ndarray:
        """–†–∏—Å—É–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        result_image = image.copy()
        
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            class_name = detection['class']
            confidence = detection['confidence']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∞
            color = self.colors.get(class_name, (128, 128, 128))
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(result_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            label = f"{class_name}: {confidence:.2f}"
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            
            # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(
                result_image,
                (int(x1), int(y1) - text_height - baseline - 5),
                (int(x1) + text_width, int(y1)),
                color,
                -1
            )
            
            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
            cv2.putText(
                result_image,
                label,
                (int(x1), int(y1) - baseline - 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )
        
        return result_image

    def process_video(self, video_path: str, output_path: str, confidence_threshold: float = 0.5, skip_frames: int = 1):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –¥–µ—Ñ–µ–∫—Ç–∞–º–∏
        
        Args:
            video_path: –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            confidence_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            skip_frames: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä (–¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)
        
        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        cap = cv2.VideoCapture(video_path)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–µ–∫ –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ (H.264 –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –±—Ä–∞—É–∑–µ—Ä–∞–º–∏)
        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264 –∫–æ–¥–µ–∫
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        processed_frames = 0
        total_detections = 0
        defect_summary = {}
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤, {fps} FPS")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–π skip_frames –∫–∞–¥—Ä
            if frame_count % skip_frames == 0:
                # –î–µ—Ç–µ–∫—Ü–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤
                detections = self.detect_defects(frame, confidence_threshold)
                
                # –†–∏—Å—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
                if detections:
                    frame = self.draw_detections(frame, detections)
                    total_detections += len(detections)
                    
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã –¥–µ—Ñ–µ–∫—Ç–æ–≤
                    for detection in detections:
                        defect_type = detection['class']
                        defect_summary[defect_type] = defect_summary.get(defect_type, 0) + 1
                
                processed_frames += 1
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if processed_frames % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({frame_count}/{total_frames})")
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä –≤ –≤—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ
            out.write(frame)
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        cap.release()
        out.release()
        
        return {
            'total_frames': total_frames,
            'processed_frames': processed_frames,
            'total_detections': total_detections,
            'defect_summary': defect_summary,
            'output_path': output_path
        }

    def extract_frames_with_defects(self, video_path: str, output_dir: str, confidence_threshold: float = 0.5, max_frames: int = 10):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã —Å –¥–µ—Ñ–µ–∫—Ç–∞–º–∏ –∏–∑ –≤–∏–¥–µ–æ
        
        Args:
            video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
            output_dir: –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤
            confidence_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            max_frames: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        
        Returns:
            list: —Å–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–µ—Ñ–µ–∫—Ç–∞—Ö
        """
        cap = cv2.VideoCapture(video_path)
        
        os.makedirs(output_dir, exist_ok=True)
        
        frame_count = 0
        saved_frames = []
        
        while len(saved_frames) < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤
            detections = self.detect_defects(frame, confidence_threshold)
            
            if detections:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä —Å –¥–µ—Ñ–µ–∫—Ç–∞–º–∏
                timestamp = frame_count / cap.get(cv2.CAP_PROP_FPS)
                filename = f"defect_frame_{frame_count:06d}_{timestamp:.2f}s.jpg"
                filepath = os.path.join(output_dir, filename)
                
                # –†–∏—Å—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                frame_with_detections = self.draw_detections(frame, detections)
                cv2.imwrite(filepath, frame_with_detections)
                
                saved_frames.append({
                    'frame_number': frame_count,
                    'timestamp': timestamp,
                    'filename': filename,
                    'detections': detections,
                    'defect_count': len(detections)
                })
        
        cap.release()
        return saved_frames


# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False
CORS(app)  # –†–∞–∑—Ä–µ—à–∞–µ–º CORS –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
MODEL_PATH = Path(__file__).parent / "models" / "paint_defect.pt"
detector = None

try:
    if MODEL_PATH.exists():
        detector = PaintDefectDetector(str(MODEL_PATH))
    else:
        print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")
        print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python utils/train_model.py")
except Exception as e:
    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {e}")

@app.route('/temp/<filename>', methods=['GET', 'OPTIONS'])
def serve_temp_file(filename):
    """–°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ temp —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Range requests"""
    if request.method == 'OPTIONS':
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ preflight –∑–∞–ø—Ä–æ—Å–æ–≤
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Range'
        return response
    
    temp_dir = Path(__file__).parent / "temp"
    file_path = temp_dir / filename
    
    if not file_path.exists():
        return jsonify({'error': 'File not found'}), 404
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    file_size = file_path.stat().st_size
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Range –∑–∞–≥–æ–ª–æ–≤–æ–∫
    range_header = request.headers.get('Range', None)
    if range_header:
        # –ü–∞—Ä—Å–∏–º Range –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "bytes=0-1023")
        byte_start = 0
        byte_end = file_size - 1
        
        if range_header.startswith('bytes='):
            range_match = range_header[6:].split('-')
            if range_match[0]:
                byte_start = int(range_match[0])
            if range_match[1]:
                byte_end = int(range_match[1])
        
        # –ß–∏—Ç–∞–µ–º –Ω—É–∂–Ω—É—é —á–∞—Å—Ç—å —Ñ–∞–π–ª–∞
        with open(file_path, 'rb') as f:
            f.seek(byte_start)
            data = f.read(byte_end - byte_start + 1)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç–≤–µ—Ç —Å —á–∞—Å—Ç–∏—á–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        response = Response(
            data,
            206,  # Partial Content
            headers={
                'Content-Range': f'bytes {byte_start}-{byte_end}/{file_size}',
                'Accept-Ranges': 'bytes',
                'Content-Length': str(len(data)),
                'Content-Type': 'video/mp4',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type, Range',
            }
        )
        return response
    else:
        # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ Range
        response = send_from_directory(temp_dir, filename)
        # –î–æ–±–∞–≤–ª—è–µ–º CORS –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É Range
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Range'
        response.headers['Accept-Ranges'] = 'bytes'
        return response

@app.route('/')
def index():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API"""
    return jsonify({
        'name': 'Paint Defect Detection API',
        'version': '1.0.0',
        'description': 'REST API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –æ–∫—Ä–∞—Å–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π',
        'endpoints': {
            'POST /api/detect': '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏',
            'POST /api/detect_video': '–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ',
            'GET /api/model_info': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏',
            'GET /api/health': '–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è API'
        },
        'model_loaded': detector is not None,
        'gemini_loaded': gemini_model is not None,
        'timestamp': datetime.now().isoformat()
    })


@app.route('/api/detect', methods=['POST'])
def detect_defects():
    """API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    
    if detector is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ü–∏–∏ (detector) –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.', 'success': False}), 500
    
    if gemini_model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å Gemini –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API-–∫–ª—é—á.', 'success': False}), 500
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if 'image' not in request.files:
            return jsonify({
                'error': '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'success': False
            }), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({
                'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω',
                'success': False
            }), 400
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        confidence_threshold = float(request.form.get('confidence', 0.5))
        generate_report = request.form.get('generate_report', 'false').lower() == 'true'
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_bytes = file.read()

        image = Image.open(io.BytesIO(image_bytes))
        
        image_np = np.array(image)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR –¥–ª—è OpenCV
        if len(image_np.shape) == 3:
            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        
        # –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –¥–µ—Ñ–µ–∫—Ç—ã
        detections = detector.detect_defects(image_np, confidence_threshold)
        
        # –†–∏—Å—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_image = detector.draw_detections(image_np, detections)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ base64
        _, buffer = cv2.imencode('.jpg', result_image)
        result_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        defect_counts = {}
        for detection in detections:
            class_name = detection['class']
            defect_counts[class_name] = defect_counts.get(class_name, 0) + 1
            

        total_defects = len(detections)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        detection_record = {
            'timestamp': datetime.now().isoformat(),
            'total_defects': total_defects,
            'defect_counts': defect_counts,
            'confidence_threshold': confidence_threshold
        }
        save_detection_data(detection_record)

        gemini_report = ""
        if generate_report:
            ml_output_data = {
                'success': True,
                'detections': detections,
                'class_counts': defect_counts, 
                'total_defects': total_defects,
                'image_with_detections_available': True 
            }

            json_string = json.dumps(ml_output_data, ensure_ascii=False, indent=2)

            gemini_user_prompt_text = f"""
            Here is the JSON_DATA from our local detection model:
            ```json
            {json_string}
            Please analyze this JSON_DATA along with the provided user IMAGE and generate the final report as per your instructions. """
            
            image_pil_for_mime = Image.open(io.BytesIO(image_bytes))
            image_mime_type = Image.MIME.get(image_pil_for_mime.format)

            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            if image_mime_type not in ['image/jpeg', 'image/png']:
                image_mime_type = 'image/jpeg' # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPEG –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            image_part = {
                "mime_type": image_mime_type,
                "data": image_bytes
            }

            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫: [—Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]
                response = gemini_model.generate_content([
                    gemini_user_prompt_text, # –ß–∞—Å—Ç—å 1: –¢–µ–∫—Å—Ç (JSON)
                    image_part               # –ß–∞—Å—Ç—å 2: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                ])
                gemini_report = response.text
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API: {e}")
                gemini_report = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç."
            
        # –¥–∞–Ω–Ω—ã–µ —Ñ—Ä–æ–Ω—Ç—É
        response_data = ({
            'success': True,
            'detections': detections,       # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'defect_counts': defect_counts, # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'total_defects': total_defects, # –û—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'result_image': result_base64,  # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            'gemini_report': gemini_report, # <-- –û—Ç—á–µ—Ç –æ—Ç Gemini
            'timestamp': datetime.now().isoformat()
        })

        json_string = json.dumps(response_data, ensure_ascii=False)

        return Response(json_string, mimetype='application/json; charset=utf-8')


    
    except Exception as e:
        return jsonify({
            'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}',
            'success': False
        }), 500


@app.route('/api/detect_video', methods=['POST'])
def detect_video():
    """API –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ"""
    
    if detector is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.', 'success': False}), 500
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if 'video' not in request.files:
            return jsonify({
                'error': '–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω',
                'success': False
            }), 400
        
        file = request.files['video']
        if file.filename == '':
            return jsonify({
                'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω',
                'success': False
            }), 400
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        confidence_threshold = float(request.form.get('confidence', 0.5))
        skip_frames = int(request.form.get('skip_frames', 2))  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π 2-–π –∫–∞–¥—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        extract_frames = request.form.get('extract_frames', 'false').lower() == 'true'
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏
        temp_dir = Path(__file__).parent / "temp"
        temp_dir.mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        input_filename = f"input_video_{timestamp}.mp4"
        input_path = temp_dir / input_filename
        file.save(str(input_path))
        
        # –ü—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        output_filename = f"processed_video_{timestamp}.mp4"
        output_path = temp_dir / output_filename
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ: {input_path}")
        processing_stats = detector.process_video(
            str(input_path), 
            str(output_path), 
            confidence_threshold, 
            skip_frames
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã —Å –¥–µ—Ñ–µ–∫—Ç–∞–º–∏ (–µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ)
        extracted_frames = []
        if extract_frames and processing_stats['total_detections'] > 0:
            frames_dir = temp_dir / f"frames_{timestamp}"
            extracted_frames = detector.extract_frames_with_defects(
                str(input_path), 
                str(frames_dir), 
                confidence_threshold, 
                max_frames=5
            )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –≤ base64 (–¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ)
        video_url = None
        if output_path.exists():
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º URL –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É
            video_url = f"http://localhost:5000/temp/{output_filename}"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã –≤ base64
        frames_base64 = []
        for frame_info in extracted_frames:
            frame_path = Path(frame_info['filename'])
            if frame_path.exists():
                with open(frame_path, 'rb') as img_file:
                    img_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                    frames_base64.append({
                        'timestamp': frame_info['timestamp'],
                        'frame_number': frame_info['frame_number'],
                        'defect_count': frame_info['defect_count'],
                        'image_base64': img_base64,
                        'detections': frame_info['detections']
                    })
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ)
        try:
            if input_path.exists():
                input_path.unlink()
            # –ù–ï —É–¥–∞–ª—è–µ–º output_path, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω—É–∂–µ–Ω –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –ø–æ URL
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
        
        return jsonify({
            'success': True,
            'processing_stats': processing_stats,
            'video_url': video_url,
            'output_filename': output_filename if video_url else None,
            'extracted_frames': frames_base64,
            'summary': {
                'total_frames': processing_stats['total_frames'],
                'processed_frames': processing_stats['processed_frames'],
                'total_detections': processing_stats['total_detections'],
                'defect_types': list(processing_stats['defect_summary'].keys()),
                'defect_counts': processing_stats['defect_summary']
            },
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        return jsonify({
            'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {str(e)}',
            'success': False
        }), 500


@app.route('/api/model_info')
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if detector is None:
        return jsonify({
            'loaded': False,
            'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'
        })
    
    return jsonify({
        'loaded': True,
        'model_path': str(detector.model_path),
        'classes': detector.class_names,
        'colors': {k: [int(c) for c in v] for k, v in detector.colors.items()}
    })


@app.route('/api/health')
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': detector is not None,
        'timestamp': datetime.now().isoformat()
    })


@app.errorhandler(413)
def too_large(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    return jsonify({
        'error': '–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 16MB',
        'success': False
    }), 413


@app.errorhandler(404)
def not_found(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ 404 –æ—à–∏–±–æ–∫"""
    return jsonify({
        'error': 'Endpoint –Ω–µ –Ω–∞–π–¥–µ–Ω',
        'success': False,
        'available_endpoints': [
            'GET /',
            'POST /api/detect',
            'POST /api/detect_video',
            'GET /api/model_info',
            'GET /api/health'
        ]
    }), 404


@app.errorhandler(500)
def internal_error(e):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –æ—à–∏–±–æ–∫"""
    return jsonify({
        'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞',
        'success': False
    }), 500


@app.route('/api/stats', methods=['GET'])
def get_stats():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–µ—Ñ–µ–∫—Ç–æ–≤."""
    if not DATA_STORAGE_PATH.exists():
        return jsonify([])

    try:
        with open(DATA_STORAGE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return jsonify(data)
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return jsonify({"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"}), 500

if __name__ == '__main__':
    print("="*60)
    print("–°–ò–°–¢–ï–ú–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –î–ï–§–ï–ö–¢–û–í –û–ö–†–ê–°–ö–ò –ê–í–¢–û–ú–û–ë–ò–õ–ï–ô")
    print("="*60)
    
    if detector is not None:
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print(f"   –ö–ª–∞—Å—Å—ã –¥–µ—Ñ–µ–∫—Ç–æ–≤: {', '.join(detector.class_names)}")
    else:
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        print("   –î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print("   1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ .env —Ñ–∞–π–ª —Å API –∫–ª—é—á–æ–º Roboflow")
        print("   2. python utils/merge_datasets.py")
        print("   3. python utils/train_model.py")
    
    print("\nüåê –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞...")
    print("   URL: http://localhost:5000")
    print("   –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    print("="*60)
    
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=True,
        threaded=True
    )